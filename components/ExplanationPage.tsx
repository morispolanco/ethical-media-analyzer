
import React from 'react';
import { ChevronLeftIcon, LightbulbIcon } from './icons';

interface ExplanationPageProps {
  onNavigateBack: () => void;
}

const Section: React.FC<{ title: string; children: React.ReactNode }> = ({ title, children }) => (
    <div className="mb-8">
        <h2 className="text-2xl font-bold text-slate-800 dark:text-slate-100 mb-3 border-b-2 border-blue-500 pb-2">{title}</h2>
        <div className="space-y-4 text-slate-600 dark:text-slate-300 text-lg leading-relaxed">
            {children}
        </div>
    </div>
);

const Source: React.FC<{ citation: string }> = ({ citation }) => (
    <li className="ml-4 pl-4 border-l-2 border-slate-300 dark:border-slate-600">
        <p className="text-slate-600 dark:text-slate-400 font-mono text-base">{citation}</p>
    </li>
);

export const ExplanationPage: React.FC<ExplanationPageProps> = ({ onNavigateBack }) => {
    return (
        <div className="bg-white dark:bg-slate-800 p-6 sm:p-8 rounded-xl shadow-lg">
            <div className="flex items-center justify-between mb-6">
                <h1 className="text-3xl md:text-4xl font-bold text-slate-900 dark:text-white">
                    Methodology
                </h1>
                <button
                    onClick={onNavigateBack}
                    className="flex items-center gap-2 px-4 py-2 bg-slate-200 dark:bg-slate-700 text-slate-700 dark:text-slate-200 font-semibold rounded-lg shadow-sm hover:bg-slate-300 dark:hover:bg-slate-600 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 dark:focus:ring-offset-slate-900 transition-colors"
                    aria-label="Back to analyzer"
                >
                    <ChevronLeftIcon className="h-5 w-5" />
                    <span className="hidden sm:inline">Back</span>
                </button>
            </div>
            
            <p className="text-lg text-slate-600 dark:text-slate-300 mb-8">
                This tool provides an AI-driven ethical analysis of media content. It is designed to be a supplementary tool to encourage critical thinking, not as a definitive moral or ethical judgment. Here’s how it works.
            </p>

            <Section title="The AI Engine">
                <p>
                    The core of this analyzer is Google's <strong>Gemini 2.5 Flash</strong>, a sophisticated Large Language Model (LLM). The AI is given a detailed set of instructions—a "system prompt"—that guides it to act as an expert in media ethics. It analyzes the provided title or transcript based on this framework, not on pre-existing opinions or a database of reviews.
                </p>
            </Section>

            <Section title="The Analytical Framework">
                <p>
                    The AI evaluates content across several key thematic areas derived from established media and communication studies. These themes include:
                </p>
                <ul className="list-disc list-inside space-y-2 mt-4 text-slate-600 dark:text-slate-300">
                    <li><strong>Language and Communication:</strong> Examines dialogue for respect, hate speech, and healthy vs. toxic communication styles.</li>
                    <li><strong>Behavioral Modeling:</strong> Analyzes whether the content promotes harmful behaviors (e.g., violence, substance abuse) or pro-social ones.</li>
                    <li><strong>Social Relationships:</strong> Assesses the portrayal of family, friendships, and romantic relationships.</li>
                    <li><strong>Representation and Stereotyping:</strong> Evaluates the diversity of characters and whether the content reinforces or challenges harmful stereotypes.</li>
                    <li><strong>Positive Ethical Aspects:</strong> Identifies pro-social messages, positive values, or ethical lessons.</li>
                    <li><strong>Target Audience Appropriateness:</strong> Considers the content's suitability for different age groups.</li>
                </ul>
            </Section>

            <Section title="The 'Concern Level' Metric">
                <p>
                    The "Concern Level" is a quantitative score (0-100%) generated by the AI for the overall content and for each theme. It represents the model's synthesized assessment of the potential for ethical issues.
                </p>
                <div className="mt-4 p-4 bg-slate-50 dark:bg-slate-700/50 rounded-lg">
                    <p>
                        A <strong>low percentage</strong> suggests few ethical concerns, while a <strong>high percentage</strong> indicates the presence of significant ethical issues that may warrant viewer caution and critical discussion. This metric is a tool for highlighting areas of potential concern, not an absolute measure of quality or "unethicality."
                    </p>
                </div>
            </Section>
            
            <Section title="Disclaimer and Limitations">
                <div className="p-4 border-l-4 border-yellow-500 bg-yellow-50 dark:bg-yellow-900/30 text-yellow-800 dark:text-yellow-200">
                    <div className="flex">
                        <div className="flex-shrink-0">
                            <LightbulbIcon className="h-6 w-6 text-yellow-500" />
                        </div>
                        <div className="ml-3">
                            <p className="font-bold">Important Considerations</p>
                            <ul className="list-disc list-inside mt-2">
                                <li><strong>AI is a Tool, Not a Judge:</strong> The analysis is generated by an AI and can have inaccuracies or biases.</li>
                                <li><strong>Context is Key:</strong> The AI may miss subtle context, satire, or irony that a human viewer would understand.</li>
                                <li><strong>Use for Critical Thinking:</strong> This report is a starting point for discussion, not a final verdict. Always engage with media critically and form your own informed opinions.</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </Section>

            <Section title="Further Reading and Sources">
                 <p>The analytical framework is informed by established research in media effects, communication theory, and algorithmic ethics. For deeper understanding, we recommend the following sources:</p>
                <ul className="space-y-4 mt-4">
                    <Source citation="Noble, S. U. (2018). Algorithms of Oppression: How Search Engines Reinforce Racism. New York University Press." />
                    <Source citation="O'Neil, C. (2016). Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown." />
                    <Source citation="Potter, W. J. (2019). Media Effects. Sage Publications." />
                    <Source citation="Valkenburg, P. M., & Piotrowski, J. T. (2017). Plugged in: How media shape our lives from toddlers to king agers. Yale University Press." />
                </ul>
            </Section>

             <div className="mt-10 pt-6 border-t border-slate-200 dark:border-slate-700 flex justify-center">
                <button
                    onClick={onNavigateBack}
                    className="flex items-center gap-2 px-6 py-3 bg-blue-600 text-white font-semibold rounded-lg shadow-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 dark:focus:ring-offset-slate-900 transition-colors"
                >
                    <ChevronLeftIcon className="h-5 w-5" />
                    Back to Analyzer
                </button>
            </div>
        </div>
    );
};
